{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from pickle import dump\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierLSTM(nn.Module):\n",
    "    def __init__(self, device, context_frames):\n",
    "        super(ClassifierLSTM, self).__init__()\n",
    "        self.device = device\n",
    "        self.context_frames = context_frames\n",
    "        self.lstm = nn.LSTM(32, 200).to(device)  # tactile\n",
    "        self.fc1 = nn.Linear(200, 40).to(device)\n",
    "        self.fc2 = nn.Linear(40, 1).to(device)\n",
    "        self.tanh_activation = nn.Tanh().to(device)\n",
    "        self.relu_activation = nn.ReLU().to(device)\n",
    "        self.softmax_activation = nn.Softmax(dim=1).to(device) #we don't use this because BCE loss in pytorch automatically applies the the Sigmoid activation\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "    def forward(self, tactiles):\n",
    "        batch_size__ = tactiles.shape[1]\n",
    "        hidden = (torch.zeros(1, batch_size__, 200, device=torch.device('cuda')), torch.zeros(1, batch_size__, 200, device=torch.device('cuda')))\n",
    "        lstm_out, self.hidden_lstm = self.lstm(tactiles, hidden)\n",
    "        lstm_out_drop = self.dropout(lstm_out[-1])\n",
    "        fc1_out = self.relu_activation(self.fc1(lstm_out_drop))\n",
    "        fc1_out_drop = self.dropout(fc1_out)\n",
    "        fc2_out = self.tanh_activation(self.fc2(fc1_out_drop))\n",
    "\n",
    "        return fc2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/kia/Kiyanoush/UoLincoln/Projects/Tactile_control/tactile_prediction/uninversal_trainer/ACTP/saved_models/model_23_02_2022_10_38/test_results_slip'\n",
    "files = sorted(glob.glob(data_dir + '/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, file in enumerate(files):\n",
    "    if index == 0:\n",
    "        t10_prediction_full = np.load(file + '/prediction_data.npy')[:, :, :32]\n",
    "        slip_data_full = np.load(file + '/slip_data.npy')\n",
    "    else:\n",
    "        t10_prediction = np.load(file + '/prediction_data.npy')[:, :, :32]\n",
    "        slip_data = np.load(file + '/slip_data.npy')\n",
    "        t10_prediction_full = np.concatenate((t10_prediction_full, t10_prediction), axis=0)\n",
    "        slip_data_full = np.concatenate((slip_data_full, slip_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188512, 10, 32)\n"
     ]
    }
   ],
   "source": [
    "print(t10_prediction_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detemporalize(X_seq):\n",
    "    x_2d = np.zeros((X_seq.shape[0] * X_seq.shape[1], X_seq.shape[2]))\n",
    "    for index, seq in enumerate(X_seq):\n",
    "        x_2d[10*index:10*(index+1)] = seq\n",
    "       \n",
    "    return x_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(t10_prediction_full, slip_data_full, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train_2d = detemporalize(X_train)\n",
    "X_test_2d = detemporalize(X_test)\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(X_train_2d)\n",
    "X_train = scaler.transform(X_train_2d)\n",
    "X_test = scaler.transform(X_test_2d)\n",
    "dump(scaler, open('classifier_standard_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporalize(data_2d, seq_len):\n",
    "    x_3d = np.zeros((int(data_2d.shape[0] / seq_len), seq_len, data_2d.shape[1]))\n",
    "    for index in range(x_3d.shape[0]):\n",
    "        x_3d[index] = data_2d[10*index:10*(index+1)]\n",
    "    \n",
    "    return x_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = temporalize(X_train, 10)\n",
    "X_test = temporalize(X_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131958, 10, 32)\n",
      "(56554, 10, 32)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data\n",
    "class TrainData(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "train_data = TrainData(X_train, y_train)\n",
    "\n",
    "## test data    \n",
    "class TestData(Dataset):    \n",
    "    def __init__(self, X_data):\n",
    "        self.X_data = X_data\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index]\n",
    "\n",
    "    def __len__ (self):\n",
    "        return len(self.X_data)\n",
    "    \n",
    "test_data = TestData(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "ClassifierLSTM(\n",
      "  (lstm): LSTM(32, 200)\n",
      "  (fc1): Linear(in_features=200, out_features=40, bias=True)\n",
      "  (fc2): Linear(in_features=40, out_features=1, bias=True)\n",
      "  (tanh_activation): Tanh()\n",
      "  (relu_activation): ReLU()\n",
      "  (softmax_activation): Softmax(dim=1)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = ClassifierLSTM(device, context_frames=10)\n",
    "model.to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195281\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    \n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001: | Loss: 0.35810 | Train Acc: 95.579 | Val Acc: 97.639 | saved model\n",
      "Epoch 002: | Loss: 0.33577 | Train Acc: 97.745 | Val Acc: 98.175 | saved model\n",
      "Epoch 003: | Loss: 0.33276 | Train Acc: 98.051 | Val Acc: 98.168 | \n",
      "Epoch 004: | Loss: 0.33065 | Train Acc: 98.247 | Val Acc: 98.371 | saved model\n",
      "Epoch 005: | Loss: 0.32977 | Train Acc: 98.370 | Val Acc: 98.665 | saved model\n",
      "Epoch 006: | Loss: 0.32972 | Train Acc: 98.369 | Val Acc: 98.739 | saved model\n",
      "Epoch 007: | Loss: 0.32797 | Train Acc: 98.536 | Val Acc: 98.478 | \n",
      "Epoch 008: | Loss: 0.32692 | Train Acc: 98.646 | Val Acc: 98.799 | saved model\n",
      "Epoch 009: | Loss: 0.32672 | Train Acc: 98.677 | Val Acc: 98.333 | \n",
      "Epoch 010: | Loss: 0.32633 | Train Acc: 98.702 | Val Acc: 98.713 | \n",
      "Epoch 011: | Loss: 0.32562 | Train Acc: 98.771 | Val Acc: 98.838 | saved model\n",
      "Epoch 012: | Loss: 0.32591 | Train Acc: 98.757 | Val Acc: 98.787 | \n",
      "Epoch 013: | Loss: 0.32515 | Train Acc: 98.828 | Val Acc: 98.814 | \n",
      "Epoch 014: | Loss: 0.32594 | Train Acc: 98.758 | Val Acc: 98.886 | saved model\n",
      "Epoch 015: | Loss: 0.32497 | Train Acc: 98.842 | Val Acc: 98.969 | saved model\n",
      "Epoch 016: | Loss: 0.32458 | Train Acc: 98.891 | Val Acc: 98.953 | \n",
      "Epoch 017: | Loss: 0.32428 | Train Acc: 98.907 | Val Acc: 98.992 | saved model\n",
      "Epoch 018: | Loss: 0.32399 | Train Acc: 98.937 | Val Acc: 98.999 | saved model\n",
      "Epoch 019: | Loss: 0.32348 | Train Acc: 98.984 | Val Acc: 99.006 | saved model\n",
      "Epoch 020: | Loss: 0.32283 | Train Acc: 99.051 | Val Acc: 98.877 | \n",
      "Epoch 021: | Loss: 0.32400 | Train Acc: 98.936 | Val Acc: 98.897 | \n",
      "Epoch 022: | Loss: 0.32320 | Train Acc: 99.010 | Val Acc: 98.697 | \n",
      "Epoch 023: | Loss: 0.32372 | Train Acc: 98.966 | Val Acc: 98.934 | \n",
      "Epoch 024: | Loss: 0.32410 | Train Acc: 98.930 | Val Acc: 98.838 | \n",
      "Epoch 025: | Loss: 0.32324 | Train Acc: 99.021 | Val Acc: 99.061 | saved model\n",
      "Epoch 026: | Loss: 0.32470 | Train Acc: 98.875 | Val Acc: 98.833 | \n",
      "Epoch 027: | Loss: 0.32392 | Train Acc: 98.953 | Val Acc: 98.898 | \n",
      "Epoch 028: | Loss: 0.32314 | Train Acc: 99.031 | Val Acc: 98.996 | \n",
      "Epoch 029: | Loss: 0.32309 | Train Acc: 99.023 | Val Acc: 99.172 | saved model\n",
      "Epoch 030: | Loss: 0.32233 | Train Acc: 99.101 | Val Acc: 99.199 | saved model\n",
      "Epoch 031: | Loss: 0.32250 | Train Acc: 99.087 | Val Acc: 98.964 | \n",
      "Epoch 032: | Loss: 0.32288 | Train Acc: 99.055 | Val Acc: 99.024 | \n",
      "Epoch 033: | Loss: 0.32193 | Train Acc: 99.148 | Val Acc: 99.172 | \n",
      "Epoch 034: | Loss: 0.32285 | Train Acc: 99.056 | Val Acc: 99.142 | \n",
      "Epoch 035: | Loss: 0.32286 | Train Acc: 99.059 | Val Acc: 99.063 | \n",
      "Epoch 036: | Loss: 0.32172 | Train Acc: 99.169 | Val Acc: 99.226 | saved model\n",
      "Epoch 037: | Loss: 0.32195 | Train Acc: 99.146 | Val Acc: 99.194 | \n",
      "Epoch 038: | Loss: 0.32315 | Train Acc: 99.028 | Val Acc: 98.833 | \n",
      "Epoch 039: | Loss: 0.32298 | Train Acc: 99.042 | Val Acc: 99.171 | \n",
      "Epoch 040: | Loss: 0.32172 | Train Acc: 99.159 | Val Acc: 98.881 | \n",
      "Epoch 041: | Loss: 0.32243 | Train Acc: 99.094 | Val Acc: 99.107 | \n",
      "Epoch 042: | Loss: 0.32127 | Train Acc: 99.204 | Val Acc: 99.096 | \n",
      "Epoch 043: | Loss: 0.32171 | Train Acc: 99.155 | Val Acc: 99.128 | \n",
      "Epoch 044: | Loss: 0.32179 | Train Acc: 99.156 | Val Acc: 99.024 | \n",
      "Epoch 045: | Loss: 0.32186 | Train Acc: 99.154 | Val Acc: 99.199 | \n",
      "Epoch 046: | Loss: 0.32147 | Train Acc: 99.204 | Val Acc: 99.149 | \n",
      "Epoch 047: | Loss: 0.32165 | Train Acc: 99.182 | Val Acc: 99.227 | saved model\n",
      "Epoch 048: | Loss: 0.32148 | Train Acc: 99.196 | Val Acc: 99.300 | saved model\n",
      "Epoch 049: | Loss: 0.32257 | Train Acc: 99.092 | Val Acc: 98.798 | \n",
      "Epoch 050: | Loss: 0.32217 | Train Acc: 99.126 | Val Acc: 98.967 | \n",
      "Epoch 051: | Loss: 0.32128 | Train Acc: 99.217 | Val Acc: 99.024 | \n",
      "Epoch 052: | Loss: 0.32089 | Train Acc: 99.250 | Val Acc: 99.144 | \n",
      "Epoch 053: | Loss: 0.32117 | Train Acc: 99.230 | Val Acc: 99.141 | \n",
      "Epoch 054: | Loss: 0.32120 | Train Acc: 99.223 | Val Acc: 99.206 | \n",
      "Epoch 055: | Loss: 0.32049 | Train Acc: 99.284 | Val Acc: 99.307 | saved model\n",
      "Epoch 056: | Loss: 0.32131 | Train Acc: 99.200 | Val Acc: 99.303 | \n",
      "Epoch 057: | Loss: 0.32090 | Train Acc: 99.250 | Val Acc: 99.079 | \n",
      "Epoch 058: | Loss: 0.32111 | Train Acc: 99.225 | Val Acc: 99.241 | \n",
      "Epoch 059: | Loss: 0.32057 | Train Acc: 99.284 | Val Acc: 99.155 | \n",
      "Epoch 060: | Loss: 0.32096 | Train Acc: 99.241 | Val Acc: 99.300 | \n",
      "Epoch 061: | Loss: 0.32083 | Train Acc: 99.259 | Val Acc: 99.226 | \n",
      "Epoch 062: | Loss: 0.32109 | Train Acc: 99.230 | Val Acc: 99.286 | \n",
      "Epoch 063: | Loss: 0.32073 | Train Acc: 99.259 | Val Acc: 99.137 | \n",
      "Epoch 064: | Loss: 0.32110 | Train Acc: 99.219 | Val Acc: 99.229 | \n",
      "Epoch 065: | Loss: 0.32109 | Train Acc: 99.233 | Val Acc: 99.169 | \n",
      "Epoch 066: | Loss: 0.32118 | Train Acc: 99.216 | Val Acc: 98.985 | \n",
      "Epoch 067: | Loss: 0.32122 | Train Acc: 99.222 | Val Acc: 99.254 | \n",
      "Epoch 068: | Loss: 0.32082 | Train Acc: 99.262 | Val Acc: 99.310 | saved model\n",
      "Epoch 069: | Loss: 0.32036 | Train Acc: 99.302 | Val Acc: 99.356 | saved model\n",
      "Epoch 070: | Loss: 0.32035 | Train Acc: 99.304 | Val Acc: 99.038 | \n"
     ]
    }
   ],
   "source": [
    "epochs = 70\n",
    "score_file = np.zeros((epochs, 2))\n",
    "best_val_acc = 0.0\n",
    "for e in range(1, epochs+1):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model_save = \"\"\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch = X_batch.type(torch.FloatTensor)\n",
    "        y_batch = y_batch.type(torch.FloatTensor)\n",
    "        \n",
    "        X_batch = X_batch.permute(1, 0, 2).to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(X_batch)\n",
    "        \n",
    "        loss = criterion(y_pred, y_batch.unsqueeze(1))\n",
    "        acc = binary_acc(y_pred, y_batch.unsqueeze(1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    score_file[e-1, 0] = epoch_acc/len(train_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred_list = []\n",
    "        model.eval()\n",
    "        for X_batch in test_loader:\n",
    "            X_batch = X_batch.type(torch.FloatTensor)\n",
    "            X_batch = X_batch.permute(1, 0, 2).to(device)\n",
    "            \n",
    "            X_batch = X_batch.to(device)\n",
    "            y_test_pred = model(X_batch)\n",
    "            y_test_pred = torch.sigmoid(y_test_pred)\n",
    "            y_pred_tag = torch.round(y_test_pred)\n",
    "            y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "    \n",
    "    y_pred_list = [a.squeeze().tolist() for a in y_pred_list]\n",
    "    \n",
    "    val_acc = accuracy_score(y_test, y_pred_list) * 100\n",
    "\n",
    "    score_file[e-1, 1] = val_acc\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model, 'classifier_lstm')\n",
    "        model_save = \"saved model\"\n",
    "\n",
    "\n",
    "    print(f'Epoch {e+0:03}: | Loss: {epoch_loss/len(train_loader):.5f} | Train Acc: {epoch_acc/len(train_loader):.3f} | Val Acc: {val_acc:.3f} | {model_save}')\n",
    "\n",
    "np.save('scores.npy', score_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('classifier_lstm').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        X_batch = X_batch.type(torch.FloatTensor)\n",
    "        X_batch = X_batch.permute(1, 0, 2).to(device)\n",
    "        \n",
    "        X_batch = X_batch.to(device)\n",
    "        y_test_pred = model(X_batch)\n",
    "        y_test_pred = torch.sigmoid(y_test_pred)\n",
    "        y_pred_tag = torch.round(y_test_pred)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        \n",
    "y_pred_list = [a.squeeze().tolist() for a in y_pred_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     51758\n",
      "         1.0       0.96      0.96      0.96      4796\n",
      "\n",
      "    accuracy                           0.99     56554\n",
      "   macro avg       0.98      0.98      0.98     56554\n",
      "weighted avg       0.99      0.99      0.99     56554\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 32.09375, 'Predicted class')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_list)\n",
    "LABELS = [\"non_slip\",\"slip\"]\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.heatmap(conf_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "# plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007068634033203125\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "y_pred_list = []\n",
    "model.eval()\n",
    "count = 0\n",
    "t1 = time.time()\n",
    "for X_batch, y_batch in train_loader:\n",
    "    X_batch = X_batch.type(torch.FloatTensor)\n",
    "    X_batch = X_batch.permute(1, 0, 2).to(device)\n",
    "    \n",
    "    X_batch = X_batch.to(device)\n",
    "    y_test_pred = model(X_batch)\n",
    "    y_test_pred = torch.sigmoid(y_test_pred)\n",
    "    y_pred_tag = torch.round(y_test_pred)\n",
    "    y_pred_list.append(y_pred_tag.cpu().detach().numpy())\n",
    "    t2 = time.time()\n",
    "    break\n",
    "\n",
    "print(t2-t1)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b53fcb633c9691f82046febe19aeee415856832757c230a8d8b4a8d6fbeb0243"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit ('tensorflow': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
